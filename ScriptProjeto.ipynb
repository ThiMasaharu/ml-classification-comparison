{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # visualização gráfica\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.tree import plot_tree\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def espec_sens(observado,predicts):\n",
    "    \n",
    "    # adicionar objeto com os valores dos predicts\n",
    "    # values = predicts.values\n",
    "    values = predicts\n",
    "    \n",
    "    # range dos cutoffs a serem analisados em steps de 0.01\n",
    "    cutoffs = np.arange(0,1.01,0.01)\n",
    "    \n",
    "    # Listas que receberão os resultados de especificidade e sensitividade\n",
    "    lista_sensitividade = []\n",
    "    lista_especificidade = []\n",
    "    \n",
    "    for cutoff in cutoffs:\n",
    "        \n",
    "        predicao_binaria = []\n",
    "        \n",
    "        # Definindo resultado binário de acordo com o predict\n",
    "        for item in values:\n",
    "            if item >= cutoff:\n",
    "                predicao_binaria.append(1)\n",
    "            else:\n",
    "                predicao_binaria.append(0)\n",
    "                \n",
    "        # Cálculo da sensitividade e especificidade no cutoff\n",
    "        sensitividade = recall_score(observado, predicao_binaria, pos_label=1)\n",
    "        especificidade = recall_score(observado, predicao_binaria, pos_label=0)\n",
    "        \n",
    "        # Adicionar valores nas listas\n",
    "        lista_sensitividade.append(sensitividade)\n",
    "        lista_especificidade.append(especificidade)\n",
    "        \n",
    "    # Criar dataframe com os resultados nos seus respectivos cutoffs\n",
    "    resultado = pd.DataFrame({'cutoffs':cutoffs,'sensitividade':lista_sensitividade,'especificidade':lista_especificidade})\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "df_base_nativa = pd.read_excel('DadosClientesProjeto.xlsx')\n",
    "df_base_nativa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace de valores em brancos ou espaços para NaN\n",
    "df_base_nativa.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "# confere valores NaN\n",
    "df_base_nativa.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = df_base_nativa.dropna()\n",
    "df_base.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_colunas_qualitativas = ['Segmento', 'UF', 'Municipio', 'ContratoAtivo', 'FretePadrao', 'DescCondPag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_colunas_quantitativas = ['DiasDesdePrimeiroFaturamento', 'DiasDesdeUltimoFaturamento', 'MediaMargemRelativa',\n",
    "                                'SomaValorFaturado', 'ProdutosDiferentesComprados', 'TicketMedio', 'QuantidadePedidos',\n",
    "                                'QuantidadeMesesComprando', 'TaxaConversaoOrcamentos', 'MesesConsecutivosComprando',\n",
    "                                'MediaFrete']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.groupby('Churn').describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_base.describe().T.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coluna in lista_colunas_qualitativas:\n",
    "    print(df_base[coluna].value_counts())\n",
    "    print('-=' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_clientes = len(df_base)\n",
    "\n",
    "for col in lista_colunas_qualitativas:\n",
    "    # conta o número de clientes por categoria e divide pelo número total de clientes\n",
    "    # ou seja, porcentagem de clientes por categoria\n",
    "    temp_df = pd.Series(df_base[col].value_counts() / total_clientes)\n",
    "\n",
    "    # faz um gráfico com as porcetanges obtidas\n",
    "    fig = temp_df.sort_values(ascending=False).plot.bar()\n",
    "    fig.set_xlabel(col)\n",
    "\n",
    "    # adiciona linha em 1%\n",
    "    fig.axhline(y=0.01, color='red')\n",
    "    fig.set_ylabel('Porcentagem de clientes')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_muitas_categ = ['Municipio', 'DescCondPag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupa_categorias_raras(df, var, cutoff):\n",
    "    total_clientes = len(df)\n",
    "    # calcula a porcentagem de clientes em cada categoria\n",
    "    temp_df = pd.Series(df[var].value_counts() / total_clientes)\n",
    "\n",
    "    # cria um dicionário para substituir categorias raras com string 'Outras'\n",
    "    grouping_dict = {\n",
    "        k: ('Outros' if k not in temp_df[temp_df >= cutoff].index else k)\n",
    "        for k in temp_df.index\n",
    "    }\n",
    "\n",
    "    # substitui categorias raras\n",
    "    tmp = df[var].map(grouping_dict)\n",
    "\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in lista_colunas_qualitativas:\n",
    "    if col not in qual_muitas_categ:\n",
    "        df_base[f'{col}_agrupado'] = agrupa_categorias_raras(df_base, f'{col}', 0.01)\n",
    "    elif col in qual_muitas_categ:\n",
    "        df_base[f'{col}_agrupado'] = agrupa_categorias_raras(df_base, f'{col}', 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coluna in lista_colunas_qualitativas:\n",
    "    print(df_base[f'{coluna}_agrupado'].value_counts())\n",
    "    print('-=' * 20)\n",
    "    print(df_base[f'{coluna}_agrupado'].value_counts(normalize=True).mul(100))\n",
    "    print('-=' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in lista_colunas_qualitativas:\n",
    "    print(df_base.groupby(['Churn', f'{col}_agrupado'])['Churn'].count())\n",
    "    print('-=' * 20)\n",
    "    print(df_base.groupby(['Churn', f'{col}_agrupado'])['Churn'].count().div(total_clientes).mul(100))\n",
    "    print('-=' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_base.groupby(['Churn'])['Churn'].count())\n",
    "print(df_base.groupby(['Churn'])['Churn'].count().div(total_clientes).mul(100))\n",
    "print(len(df_base['Churn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in lista_colunas_qualitativas:\n",
    "    print('Não')\n",
    "    print(df_base[df_base['Churn'] == 0][f'{col}_agrupado'].value_counts(normalize=True).mul(100))\n",
    "    print('-=' * 20)\n",
    "    print('Sim')\n",
    "    print(df_base[df_base['Churn'] == 1][f'{col}_agrupado'].value_counts(normalize=True).mul(100))\n",
    "    print('-=' * 20)\n",
    "    print(df_base.groupby(['Churn', f'{col}_agrupado'])['Churn'].count())\n",
    "    print('-=' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nova_lista_colunas_qualitativas = ['Segmento_agrupado', 'UF_agrupado', 'Municipio_agrupado', 'ContratoAtivo_agrupado', \n",
    "                                   'FretePadrao_agrupado', 'DescCondPag_agrupado']\n",
    "df_base_tratada = df_base.drop(lista_colunas_qualitativas, axis=1)\n",
    "df_base_tratada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_dummies = pd.get_dummies(df_base_tratada,\n",
    "                                 columns=nova_lista_colunas_qualitativas,\n",
    "                                 dtype=int,\n",
    "                                 drop_first=True)\n",
    "df_base_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_base_dummies.drop(columns=['Churn'])\n",
    "y = df_base_dummies['Churn']\n",
    "\n",
    "# Vamos escolher 70% das observações para treino e 30% para teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_log = LogisticRegression(random_state=100)\n",
    "np.random.seed(100)\n",
    "\n",
    "# Defining hyperparameters to search over\n",
    "params = {\n",
    "    'penalty':['l1','l2','elasticnet','none'],\n",
    "    'C' : [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'fit_intercept': [True, False],\n",
    "    'solver': ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter'  : [100, 1000, 2500, 5000, 10000]\n",
    "}\n",
    "\n",
    "# Defining randomized search\n",
    "reg_log_cv = RandomizedSearchCV(estimator=reg_log, \n",
    "                            param_distributions=params,\n",
    "                            random_state=100,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "# Fitting randomized search to training data\n",
    "reg_log_cv.fit(X_train, y_train)\n",
    "print(reg_log_cv.best_params_)\n",
    "\n",
    "# Model predictions \n",
    "y_pred_reg_log = reg_log_cv.predict(X_test)\n",
    "prob_pos = reg_log_cv.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Model performance\n",
    "reg_log_accuracy = accuracy_score(y_test, y_pred_reg_log)\n",
    "print((\"Acurácia: {:.4f}\".format(reg_log_accuracy)))\n",
    "\n",
    "reg_log_precision = precision_score(y_test, y_pred_reg_log)\n",
    "print(\"Precisão: {:.4f}\".format(reg_log_precision))\n",
    "\n",
    "reg_log_recall = recall_score(y_test, y_pred_reg_log)\n",
    "print(\"Sensitividade: {:.4f}\".format(reg_log_recall))\n",
    "\n",
    "reg_log_fpr = recall_score(y_test, y_pred_reg_log, pos_label=0)\n",
    "print(\"Especificidade: {:.4f}\".format(reg_log_fpr))\n",
    "\n",
    "reg_log_f1 = f1_score(y_test, y_pred_reg_log)\n",
    "print(\"Pontuação F1: {:.4f}\".format(reg_log_f1))\n",
    "\n",
    "reg_log_auc_value = roc_auc_score(y_test, prob_pos)\n",
    "print(\"AUC: {:.4f}\".format(reg_log_auc_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_pred_reg_log, y_test)\n",
    "cm_reg_log = ConfusionMatrixDisplay(cm)\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "cm_reg_log.plot(colorbar=False, cmap='viridis')\n",
    "plt.title('Regressão logística: Teste')\n",
    "plt.xlabel('Observado (Real)')\n",
    "plt.ylabel('Classificado (Modelo)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Até o momento, foram extraídos 3 vetores: 'sensitividade',\n",
    "#'especificidade' e 'cutoffs'. Assim, criamos um dataframe que contém\n",
    "#os vetores mencionados\n",
    "\n",
    "dados_plotagem = espec_sens(observado = y_test,\n",
    "                            predicts = y_pred_reg_log)\n",
    "dados_plotagem\n",
    "\n",
    "# Plotagem de um gráfico que mostra a variação da especificidade e da\n",
    "#sensitividade em função do cutoff\n",
    "\n",
    "plt.figure(figsize=(15,10), dpi=50)\n",
    "with plt.style.context('seaborn-v0_8-whitegrid'):\n",
    "    plt.plot(dados_plotagem.cutoffs,dados_plotagem.sensitividade, marker='o',\n",
    "         color='indigo', markersize=8)\n",
    "    plt.plot(dados_plotagem.cutoffs,dados_plotagem.especificidade, marker='o',\n",
    "         color='limegreen', markersize=8)\n",
    "plt.xlabel('Cuttoff', fontsize=20)\n",
    "plt.ylabel('Sensitividade / Especificidade', fontsize=20)\n",
    "plt.xticks(np.arange(0, 1.1, 0.2), fontsize=14)\n",
    "plt.yticks(np.arange(0, 1.1, 0.2), fontsize=14)\n",
    "plt.legend(['Sensitividade', 'Especificidade'], fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametrizando a função da curva ROC (real vs. previsto)\n",
    "fpr_reg_log, tpr_reg_log, thresholds_reg_log = roc_curve(y_test, prob_pos)\n",
    "roc_auc_xgb = auc(fpr_reg_log, tpr_reg_log)\n",
    "\n",
    "# Plotando a curva ROC\n",
    "plt.figure(figsize=(15,10), dpi=50)\n",
    "plt.plot(fpr_reg_log, tpr_reg_log, color='green', linewidth=4)\n",
    "plt.plot(fpr_reg_log, fpr_reg_log, color='gray', linestyle='dashed')\n",
    "plt.title('AUC-ROC regressão logística: %g' % round(roc_auc_xgb, 3), fontsize=22)\n",
    "plt.xlabel('1 - Especificidade', fontsize=20)\n",
    "plt.ylabel('Sensibilidade', fontsize=20)\n",
    "plt.xticks(np.arange(0, 1.1, 0.2), fontsize=14)\n",
    "plt.yticks(np.arange(0, 1.1, 0.2), fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=100)\n",
    "np.random.seed(100)\n",
    "\n",
    "params = {\n",
    "    'criterion': ['gini', 'entropy', 'logloss'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, None],\n",
    "    'min_samples_split': [2, 4, 6, 8, 10],\n",
    "    'min_samples_leaf': [1, 2, 4, 6],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "cv_dt = RandomizedSearchCV(\n",
    "    dt, \n",
    "    param_distributions=params, \n",
    "    random_state=100,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "cv_dt.fit(X_train, y_train)\n",
    "print(cv_dt.best_params_)\n",
    "\n",
    "best_dt = cv_dt.best_estimator_\n",
    "best_dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = best_dt.predict(X_test)\n",
    "prob_pos = best_dt.predict_proba(X_test)[:,1]\n",
    "\n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "print((\"Acurácia: {:.4f}\".format(dt_accuracy)))\n",
    "\n",
    "dt_precision = precision_score(y_test, y_pred_dt)\n",
    "print(\"Precisão: {:.4f}\".format(dt_precision))\n",
    "\n",
    "dt_recall = recall_score(y_test, y_pred_dt)\n",
    "print(\"Sensitividade: {:.4f}\".format(dt_recall))\n",
    "\n",
    "dt_fpr = recall_score(y_test, y_pred_dt, pos_label=0)\n",
    "print(\"Especificidade: {:.4f}\".format(dt_fpr))\n",
    "\n",
    "dt_f1 = f1_score(y_test, y_pred_dt)\n",
    "print(\"Pontuação F1: {:.4f}\".format(dt_f1))\n",
    "\n",
    "dt_auc_value = roc_auc_score(y_test, prob_pos)\n",
    "print(\"AUC: {:.4f}\".format(dt_auc_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10), dpi=100)\n",
    "plot_tree(best_dt,\n",
    "          feature_names=X.columns.tolist(),\n",
    "          class_names=['Não churner','Churner'],\n",
    "          proportion=False,\n",
    "          filled=True,\n",
    "          node_ids=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Matriz de confusão (base de teste)\n",
    "cm = confusion_matrix(y_pred_dt, y_test)\n",
    "cm_dt = ConfusionMatrixDisplay(cm)\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "cm_dt.plot(colorbar=False, cmap='viridis')\n",
    "plt.title('Árvore de Decisão: Teste')\n",
    "plt.xlabel('Observado (Real)')\n",
    "plt.ylabel('Classificado (Modelo)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=100)\n",
    "np.random.seed(100)\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [10, 20, 50, 100, 200, 400],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, None],\n",
    "    'min_samples_split': [2, 4, 6, 8, 10],\n",
    "    'min_samples_leaf': [1, 2, 4, 6],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False],\n",
    "    'oob_score': [True, False],\n",
    "}\n",
    "\n",
    "cv_rf = RandomizedSearchCV(\n",
    "    rf,\n",
    "    param_distributions=params,\n",
    "    random_state=100,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "cv_rf.fit(X_train, y_train)\n",
    "print(cv_rf.best_params_)\n",
    "\n",
    "# Model predictions\n",
    "y_pred_rf = cv_rf.predict(X_test)\n",
    "prob_pos = cv_rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print((\"Acurácia: {:.4f}\".format(rf_accuracy)))\n",
    "\n",
    "rf_precision = precision_score(y_test, y_pred_rf)\n",
    "print(\"Precisão: {:.4f}\".format(rf_precision))\n",
    "\n",
    "rf_recall = recall_score(y_test, y_pred_rf)\n",
    "print(\"Sensitividade: {:.4f}\".format(rf_recall))\n",
    "\n",
    "rf_fpr = recall_score(y_test, y_pred_rf, pos_label=0)\n",
    "print(\"Especificidade: {:.4f}\".format(rf_fpr))\n",
    "\n",
    "rf_f1 = f1_score(y_test, y_pred_rf)\n",
    "print(\"Pontuação F1: {:.4f}\".format(rf_f1))\n",
    "\n",
    "rf_auc_value = roc_auc_score(y_test, prob_pos)\n",
    "print(\"AUC: {:.4f}\".format(rf_auc_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_pred_rf, y_test)\n",
    "cm_rf = ConfusionMatrixDisplay(cm)\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "cm_rf.plot(colorbar=False, cmap='viridis')\n",
    "plt.title('Random forest: Teste')\n",
    "plt.xlabel('Observado (Real)')\n",
    "plt.ylabel('Classificado (Modelo)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(random_state=100)\n",
    "np.random.seed(100)\n",
    "\n",
    "params = {\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    'n_estimators': [50, 100, 200, 300, 400, 500],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'min_child_weight': [1, 3, 5, 7, 9],\n",
    "    'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'objective': ['reg:squarederror', 'reg:squaredlogerror', 'reg:logistic', \n",
    "                  'binary:logistic', 'binary:logitraw', 'binary:hinge',\n",
    "                  'multi:softmax', 'multi:softprob'],\n",
    "    'eval_metric': ['rmse', 'mae', 'logloss', 'error', 'merro',\n",
    "                    'mlogloss', 'auc', 'aucpr'],\n",
    "}\n",
    "\n",
    "cv_xgb = RandomizedSearchCV(\n",
    "    xgb,\n",
    "    param_distributions=params,\n",
    "    random_state=100,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "cv_xgb.fit(X_train, y_train)\n",
    "print(cv_xgb.best_params_)\n",
    "\n",
    "# Mode predictions \n",
    "y_pred_xgb = cv_xgb.predict(X_test)\n",
    "prob_pos = cv_xgb.predict_proba(X_test)[:,1]\n",
    "\n",
    "xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "print((\"Acurácia: {:.4f}\".format(xgb_accuracy)))\n",
    "\n",
    "xgb_precision = precision_score(y_test, y_pred_xgb)\n",
    "print(\"Precisão: {:.4f}\".format(xgb_precision))\n",
    "\n",
    "xgb_recall = recall_score(y_test, y_pred_xgb)\n",
    "print(\"Sensitividade: {:.4f}\".format(xgb_recall))\n",
    "\n",
    "xgb_fpr = recall_score(y_test, y_pred_xgb, pos_label=0)\n",
    "print(\"Especificidade: {:.4f}\".format(xgb_fpr))\n",
    "\n",
    "xgb_f1 = f1_score(y_test, y_pred_xgb)\n",
    "print(\"Pontuação F1: {:.4f}\".format(xgb_f1))\n",
    "\n",
    "xgb_auc_value = roc_auc_score(y_test, prob_pos)\n",
    "print(\"AUC: {:.4f}\".format(xgb_auc_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_pred_xgb, y_test)\n",
    "cm_xgb = ConfusionMatrixDisplay(cm)\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "cm_xgb.plot(colorbar=False, cmap='viridis')\n",
    "plt.title('Random forest: Teste')\n",
    "plt.xlabel('Observado (Real)')\n",
    "plt.ylabel('Classificado (Modelo)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gere suas predições separadas para cada modelo\n",
    "# Exemplo (substitua pelos seus próprios):\n",
    "# y_pred_log, y_pred_dt, y_pred_rf, y_pred_xgb = ...\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))  # Cria grid 2x2\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.4)  # Espaçamento entre os subplots\n",
    "\n",
    "# 1. Regressão Logística\n",
    "cm = confusion_matrix(y_test, y_pred_reg_log)\n",
    "ConfusionMatrixDisplay(cm).plot(ax=axes[0, 0], colorbar=False, cmap='viridis')\n",
    "axes[0, 0].set_title('Regressão logística: Teste')\n",
    "axes[0, 0].set_xlabel('Observado (Real)')\n",
    "axes[0, 0].set_ylabel('Classificado (Modelo)')\n",
    "\n",
    "# 2. Árvore de Decisão\n",
    "cm = confusion_matrix(y_test, y_pred_dt)\n",
    "ConfusionMatrixDisplay(cm).plot(ax=axes[0, 1], colorbar=False, cmap='viridis')\n",
    "axes[0, 1].set_title('Árvore de Decisão: Teste')\n",
    "axes[0, 1].set_xlabel('Observado (Real)')\n",
    "axes[0, 1].set_ylabel('Classificado (Modelo)')\n",
    "\n",
    "# 3. Random Forest\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "ConfusionMatrixDisplay(cm).plot(ax=axes[1, 0], colorbar=False, cmap='viridis')\n",
    "axes[1, 0].set_title('Random Forest: Teste')\n",
    "axes[1, 0].set_xlabel('Observado (Real)')\n",
    "axes[1, 0].set_ylabel('Classificado (Modelo)')\n",
    "\n",
    "# 4. XGBoost\n",
    "cm = confusion_matrix(y_test, y_pred_xgb)\n",
    "ConfusionMatrixDisplay(cm).plot(ax=axes[1, 1], colorbar=False, cmap='viridis')\n",
    "axes[1, 1].set_title('XGBoost: Teste')\n",
    "axes[1, 1].set_xlabel('Observado (Real)')\n",
    "axes[1, 1].set_ylabel('Classificado (Modelo)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
